# Open-webui com Ollama integrado

networks:
  default:
    name: docker-network
    external: false

services:
  ollama:
      image: ghcr.io/open-webui/open-webui:ollama
      runtime: amd
      restart: unless-stopped
      container_name: ollama
      volumes:
          - ./open-webui:/app/backend/data
          - ./ollama:/root/.ollama
      ports:
        - 8089:8080
        - 11434:11434  
      environment:
        - TZ=America/Sao_Paulo
        - OLLAMA_HOST=0.0.0.0:11434
        - AMD_VISIBLE_DEVICES=all
      devices:
        - /dev/kfd
        - /dev/dri
      security_opt:
        - seccomp=unconfined

# Acesse o Open-webui em http://localhost:8089
